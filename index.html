<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Face Unlock (face-api.js)</title>
<script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

<style>
body {
  background:#111;
  color:white;
  font-family:sans-serif;
  text-align:center;
  transition: background 0.4s;
}

#video {
  width:320px;
  border:2px solid #333;
  margin-top:20px;
}

button {
  padding:10px 20px;
  font-size:16px;
  margin-top:20px;
}

/* ğŸ“Œ å³ä¸‹ãƒ¢ãƒ¼ãƒ€ãƒ« */
#modal {
  position:fixed;
  bottom:20px;
  right:20px;
  background:#333;
  padding:15px 20px;
  border-radius:10px;
  font-size:18px;
  opacity:0;
  pointer-events:none;
  transition:opacity 0.4s;
}
#modal.show {
  opacity:1;
}

</style>
</head>
<body>

<h1>Face Unlock</h1>

<button id="startCamBtn">ã‚«ãƒ¡ãƒ©ã‚’é–‹å§‹</button><br>
<video id="video" autoplay muted playsinline></video>

<p id="status"></p>

<button id="registerBtn" style="display:none;">
  ã“ã®é¡”ã‚’ç™»éŒ²ã™ã‚‹
</button>

<button id="startAuthBtn" style="display:none;">
  èªè¨¼é–‹å§‹
</button>

<div id="modal">ç™»éŒ²ãŒå®Œäº†ã—ã¾ã—ãŸï¼</div>

<script>
let registeredDescriptor = null;
let recognitionRunning = false;

// ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
async function loadModels() {
    document.getElementById("status").innerText = "ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...";
    await faceapi.nets.tinyFaceDetector.loadFromUri("https://cdn.jsdelivr.net/npm/face-api.js/weights");
    await faceapi.nets.faceRecognitionNet.loadFromUri("https://cdn.jsdelivr.net/npm/face-api.js/weights");
    await faceapi.nets.faceLandmark68Net.loadFromUri("https://cdn.jsdelivr.net/npm/face-api.js/weights");
    document.getElementById("status").innerText = "ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†";
}
loadModels();

// ã‚«ãƒ¡ãƒ©èµ·å‹•ï¼ˆãƒœã‚¿ãƒ³å¿…é ˆï¼‰
document.getElementById("startCamBtn").onclick = async () => {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        document.getElementById("video").srcObject = stream;

        document.getElementById("status").innerText = "ã‚«ãƒ¡ãƒ©èµ·å‹•OK âœ”";
        document.getElementById("registerBtn").style.display = "inline-block";
    } catch (err) {
        document.getElementById("status").innerText = "ã‚¨ãƒ©ãƒ¼: " + err.name;
    }
};

// é¡”ç™»éŒ²
document.getElementById("registerBtn").onclick = async () => {
    const video = document.getElementById("video");
    const detection = await faceapi
        .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptor();

    if (!detection) {
        alert("é¡”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ­£é¢ã‚’å‘ã„ã¦ãã ã•ã„ã€‚");
        return;
    }

    registeredDescriptor = detection.descriptor;

    // ğŸ“Œ å³ä¸‹ãƒ¢ãƒ¼ãƒ€ãƒ«è¡¨ç¤º
    const modal = document.getElementById("modal");
    modal.classList.add("show");
    setTimeout(() => modal.classList.remove("show"), 2500);

    document.getElementById("startAuthBtn").style.display = "inline-block";
};

// èªè¨¼é–‹å§‹
document.getElementById("startAuthBtn").onclick = () => {
    recognitionRunning = true;
    document.getElementById("status").innerText = "èªè¨¼ä¸­...";
    runRecognition();
};

// èªè¨¼ãƒ«ãƒ¼ãƒ—
async function runRecognition() {
    const video = document.getElementById("video");
    const THRESHOLD = 0.45;

    setInterval(async () => {
        if (!recognitionRunning || !registeredDescriptor) return;

        const detection = await faceapi
            .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
            .withFaceLandmarks()
            .withFaceDescriptor();

        if (!detection) return;

        const distance = faceapi.euclideanDistance(
            registeredDescriptor,
            detection.descriptor
        );

        console.log("distance:", distance);

        // ğŸ“Œ ä¸€è‡´ã—ãŸã‚‰èƒŒæ™¯ã‚’é’ã«ã™ã‚‹
        if (distance < THRESHOLD) {
            document.body.style.background = "#0066ff";
        }

    }, 200);
}
</script>

</body>
</html>
