<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<title>OpenCV.js 顔認証（自動保存通知付き）</title>
<style>
  body { font-family: sans-serif; padding: 20px; }
  video, canvas { border:1px solid #333; border-radius:4px; }

  /* ---- 通知ポップアップ ---- */
  #toast {
    position: fixed;
    bottom: 20px;
    right: 20px;
    background: rgba(30, 30, 30, 0.9);
    color: #fff;
    padding: 12px 18px;
    border-radius: 8px;
    opacity: 0;
    transition: opacity .5s;
    pointer-events: none;
  }
</style>
</head>
<body>

<h2>OpenCV.js 顔認証（撮影→自動変換→モデル学習）</h2>

<button id="startCam">カメラ開始</button>
<button id="autoAdd">撮影して自動学習</button>
<button id="trainModel">モデル学習</button>

<br><br>

<video id="video" width="320" height="240" autoplay muted></video>
<canvas id="canvas" width="320" height="240"></canvas>

<p id="status">状態：待機中</p>

<div id="toast">保存しました</div>

<script async src="opencv.js" onload="onOpenCvReady();"></script>

<script>
let video = document.getElementById("video");
let canvas = document.getElementById("canvas");
let ctx = canvas.getContext("2d");

let cap;
let classifier;
let recognizer;

let trainImgs = [];     // 学習画像
let trainLabels = [];   // ラベル

function showToast(msg) {
    let t = document.getElementById("toast");
    t.textContent = msg;
    t.style.opacity = 1;
    setTimeout(() => { t.style.opacity = 0; }, 2000);
}

function onOpenCvReady() {
    document.getElementById("status").innerText = "OpenCV.js 読み込み完了";

    classifier = new cv.CascadeClassifier();
    classifier.load('haarcascade_frontalface_default.xml');

    recognizer = new cv.LBPHFaceRecognizer();
}

document.getElementById("startCam").onclick = async () => {
    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
    video.srcObject = stream;
    video.play();
    cap = new cv.VideoCapture(video);
    requestAnimationFrame(detectLoop);
};

function detectLoop() {
    let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
    let gray = new cv.Mat();

    cap.read(src);
    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

    let faces = new cv.RectVector();
    classifier.detectMultiScale(gray, faces, 1.1, 3);

    ctx.drawImage(video, 0, 0);
    if (faces.size() > 0) {
        let f = faces.get(0);
        ctx.strokeStyle = "red";
        ctx.lineWidth = 2;
        ctx.strokeRect(f.x, f.y, f.width, f.height);
    }

    src.delete(); gray.delete(); faces.delete();
    requestAnimationFrame(detectLoop);
}

document.getElementById("autoAdd").onclick = () => {

    let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
    let gray = new cv.Mat();
    cap.read(src);
    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

    let faces = new cv.RectVector();
    classifier.detectMultiScale(gray, faces, 1.1, 3);

    if (faces.size() > 0) {
        let f = faces.get(0);
        let face = gray.roi(f);

        let resized = new cv.Mat();
        cv.resize(face, resized, new cv.Size(100, 100));

        trainImgs.push(resized.clone());  // clone したものを保存
        trainLabels.push(1);

        document.getElementById("status").innerText =
            "学習画像枚数：" + trainImgs.length;

        showToast("保存完了！ (" + trainImgs.length + "枚)");

        resized.delete();
        face.delete();
    } else {
        showToast("顔が認識できませんでした");
    }

    src.delete(); gray.delete(); faces.delete();
};

document.getElementById("trainModel").onclick = () => {
    if (trainImgs.length === 0) {
        alert("学習画像がありません（撮影してください）");
        return;
    }

    recognizer.train(trainImgs, trainLabels);

    document.getElementById("status").innerText =
        "モデル学習完了。認証モードへ";

    showToast("モデル学習完了");
    requestAnimationFrame(recognizeLoop);
};

function recognizeLoop() {
    let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
    let gray = new cv.Mat();

    cap.read(src);
    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

    let faces = new cv.RectVector();
    classifier.detectMultiScale(gray, faces, 1.1, 3);

    ctx.drawImage(video, 0, 0);

    if (faces.size() > 0) {
        let f = faces.get(0);
        let face = gray.roi(f);

        let resized = new cv.Mat();
        cv.resize(face, resized, new cv.Size(100, 100));

        let result = recognizer.predict(resized);

        ctx.fillStyle = "yellow";
        ctx.font = "20px sans-serif";
        ctx.fillText(
            "ID:" + result.label + " | 信頼度:" + result.confidence,
            10, 220
        );

        resized.delete();
        face.delete();
    }

    src.delete(); gray.delete(); faces.delete();
    requestAnimationFrame(recognizeLoop);
}
</script>

</body>
</html>
